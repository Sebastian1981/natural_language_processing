{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Machine Learning Pipeline using Sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to create a sklearn pipeline in order to make life a lot easier when scoring new data i.e. articles which have to undergo the same preprocessing and modeling strategy as the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path variables\n",
    "DATAPATH = Path('data')\n",
    "MODELPATH = Path('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the Washington of 2016, even when the polic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Donald Trump has used Twitter  —   his prefe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Donald Trump is unabashedly praising Russian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Updated at 2:50 p. m. ET, Russian President Vl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From photography, illustration and video, to d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article\n",
       "0  In the Washington of 2016, even when the polic...\n",
       "1    Donald Trump has used Twitter  —   his prefe...\n",
       "2    Donald Trump is unabashedly praising Russian...\n",
       "3  Updated at 2:50 p. m. ET, Russian President Vl...\n",
       "4  From photography, illustration and video, to d..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import data\n",
    "df = pd.read_csv(DATAPATH / \"npr.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write custom tokenizer class to be passed to CountVectorizer instance \n",
    "class LemmaTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, articles):\n",
    "        lemma_tokens = [self.wnl.lemmatize(t) for t in word_tokenize(articles)]\n",
    "        lemma_tokens_alpha = [t for t in lemma_tokens if t.isalpha()]\n",
    "        return lemma_tokens_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init pipeline object\n",
    "pipe = Pipeline([('cv', CountVectorizer(lowercase=True,\n",
    "                                        stop_words='english',\n",
    "                                        tokenizer=LemmaTokenizer(),\n",
    "                                        ngram_range=(1,1),\n",
    "                                        max_df=.9, \n",
    "                                        min_df=.05,\n",
    "                                        max_features=1000 \n",
    "                                        )), \n",
    "                ('lda', LatentDirichletAllocation(n_components=10,\n",
    "                                                  random_state=123,\n",
    "                                                  n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cv',\n",
       "                 CountVectorizer(max_df=0.9, max_features=1000, min_df=0.05,\n",
       "                                 stop_words='english',\n",
       "                                 tokenizer=<__main__.LemmaTokenizer object at 0x7fa3e015b520>)),\n",
       "                ('lda',\n",
       "                 LatentDirichletAllocation(n_jobs=-1, random_state=123))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the pipeline\n",
    "pipe.fit(df.Article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the functionality of the fitted pipeline and all its components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.69250925e-02, 2.57175139e-04, 2.57153400e-04, 2.57148045e-04,\n",
       "        6.06047398e-02, 4.56062952e-02, 2.57141754e-04, 2.57145035e-04,\n",
       "        8.05320973e-01, 2.57136338e-04]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the whole pipeline ie apply it to the first article...we expect an array with topic probabilities\n",
    "pipe.transform([df['Article'][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x979 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 200 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the count vectorizer part of the pipeline ie apply it to the first article\n",
    "dtm = pipe['cv'].transform([df['Article'][0]])\n",
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/azureml_py38/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['writer',\n",
       " 'writes',\n",
       " 'writing',\n",
       " 'written',\n",
       " 'wrong',\n",
       " 'wrote',\n",
       " 'year',\n",
       " 'yes',\n",
       " 'york',\n",
       " 'young']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the terms\n",
    "pipe['cv'].get_feature_names()[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.69250925e-02, 2.57175139e-04, 2.57153400e-04, 2.57148045e-04,\n",
       "        6.06047398e-02, 4.56062952e-02, 2.57141754e-04, 2.57145035e-04,\n",
       "        8.05320973e-01, 2.57136338e-04]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the lda part of the pipeline ie apply it to the first article\n",
    "pipe['lda'].transform(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.43195650e+02, 2.34134679e+02, 6.01013378e+02, ...,\n",
       "        6.82072223e+00, 5.01368642e+02, 1.06639117e-01],\n",
       "       [1.14387199e+02, 1.98434510e+02, 1.47439641e+02, ...,\n",
       "        5.62634844e+01, 1.61976624e+02, 1.43655510e+03],\n",
       "       [2.98953324e+01, 3.09574025e+02, 4.07509224e+02, ...,\n",
       "        1.75718095e+01, 7.06604170e+01, 1.03160090e+02],\n",
       "       ...,\n",
       "       [2.77909753e+02, 6.15394106e+02, 2.30462459e+02, ...,\n",
       "        6.10713898e+01, 1.86539814e+02, 1.35200342e+02],\n",
       "       [1.10928781e+02, 1.37682785e+02, 6.74706397e+01, ...,\n",
       "        8.77417950e+01, 6.71249813e+02, 9.21314930e+00],\n",
       "       [3.63136927e+01, 7.67916003e+01, 2.43411914e+01, ...,\n",
       "        6.45430157e+01, 3.26636876e+02, 3.04070900e+02]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# have a look at the fit result i.e. the topics\n",
    "pipe['lda'].components_[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_topic(lda_obj, article_num):\n",
    "    \"\"\" input LDA object and the number of the article to be scored.\n",
    "    Return the topic number for that article\"\"\"\n",
    "    topic_num = np.argmax(lda_obj.transform(dtm[article_num]))\n",
    "    return topic_num \n",
    "\n",
    "def get_topic_terms(lda_obj, cv_obj, topic_num=0, top_n=3):\n",
    "    \"\"\" get the index position of the top 3 terms in a topic.\n",
    "    input the fitted laten dirichtlet object.\n",
    "    input the fitted count-vectorizer object.\n",
    "    input the topic number.\n",
    "    input the top-n words belonging to each topic.\n",
    "    output the top_n words for topic_num. \"\"\"\n",
    "      \n",
    "    return [cv_obj.get_feature_names_out()[ind] for ind in lda_obj.components_[topic_num].argsort()[-top_n:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The topic for article number 0 is 8\n"
     ]
    }
   ],
   "source": [
    "article_num = 0 # select article number\n",
    "top_n = 5 # select top n terms\n",
    "topic_num = get_article_topic(pipe['lda'], article_num)\n",
    "print('The topic for article number {} is {}'.format(article_num, topic_num))\n",
    "\n",
    "#top_terms = get_topic_terms(LDA, cv, topic_num, top_n)\n",
    "#print('The top {} terms in article number {} are: \\n {}'.format(top_n, article_num, top_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('azureml_py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6d65a8c07f5b6469e0fc613f182488c0dccce05038bbda39e5ac9075c0454d11"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
